services:
  # ==================== ZOOKEEPER ====================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    hostname: zookeeper
    platform: linux/arm64
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_log:/var/lib/zookeeper/log
    networks:
      - sentiment-network
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==================== KAFKA ====================
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    hostname: kafka
    platform: linux/arm64
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - sentiment-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 10

  # ==================== KAFKA UI ====================
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - sentiment-network

  # ==================== HADOOP NAMENODE ====================
  namenode:
    build:
      context: ./docker/hadoop
      dockerfile: Dockerfile.namenode
    container_name: namenode
    hostname: namenode
    ports:
      - "9870:9870"
      - "9000:9000"
    environment:
      - CLUSTER_NAME=sentiment-cluster
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    networks:
      - sentiment-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9870 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # ==================== HADOOP DATANODE ====================
  datanode:
    build:
      context: ./docker/hadoop
      dockerfile: Dockerfile.datanode
    container_name: datanode
    hostname: datanode
    depends_on:
      namenode:
        condition: service_healthy
    ports:
      - "9864:9864"
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    networks:
      - sentiment-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9864 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # ==================== SPARK MASTER ====================
  spark-master:
    build:
      context: ./docker/spark
      dockerfile: Dockerfile
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8081:8080"
      - "7077:7077"
      - "4040:4040"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - spark_data:/tmp/spark-events
    command: >
      bash -c "mkdir -p /opt/spark/logs && 
               /opt/spark/sbin/start-master.sh && 
               tail -f /dev/null"
    networks:
      - sentiment-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # ==================== SPARK WORKER ====================
  spark-worker:
    build:
      context: ./docker/spark
      dockerfile: Dockerfile
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "8082:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_WEBUI_PORT=8081
    volumes:
      - ./src:/app/src
      - ./config:/app/config
    command: >
      bash -c "mkdir -p /opt/spark/logs && 
               /opt/spark/sbin/start-worker.sh spark://spark-master:7077 && 
               tail -f /dev/null"
    networks:
      - sentiment-network

  # ==================== REDIS (Speed Layer Cache) ====================
  redis:
    image: redis:7-alpine
    container_name: redis
    hostname: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    networks:
      - sentiment-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==================== MONGODB (Serving Layer) ====================
  mongodb:
    image: mongo:6.0
    container_name: mongodb
    hostname: mongodb
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: sentiment_admin_2024
      MONGO_INITDB_DATABASE: sentiment_db
    volumes:
      - mongodb_data:/data/db
      - ./docker/mongodb/init-mongo.js:/docker-entrypoint-initdb.d/init-mongo.js:ro
    networks:
      - sentiment-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==================== REDDIT SCRAPER ====================
  reddit-scraper:
    build:
      context: .
      dockerfile: ./docker/scraper/Dockerfile
    container_name: reddit-scraper
    hostname: reddit-scraper
    depends_on:
      kafka:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - REDDIT_CLIENT_ID=${REDDIT_CLIENT_ID}
      - REDDIT_CLIENT_SECRET=${REDDIT_CLIENT_SECRET}
      - REDDIT_USER_AGENT=${REDDIT_USER_AGENT}
      - MONGODB_URI=mongodb://admin:sentiment_admin_2024@mongodb:27017
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./logs:/app/logs
    networks:
      - sentiment-network
    restart: unless-stopped

  # ==================== SPARK STREAMING (Speed Layer) ====================
  spark-streaming:
    build:
      context: .
      dockerfile: ./docker/spark-streaming/Dockerfile
    container_name: spark-streaming
    hostname: spark-streaming
    depends_on:
      spark-master:
        condition: service_healthy
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
      mongodb:
        condition: service_healthy
      namenode:
        condition: service_healthy
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MONGODB_URI=mongodb://admin:sentiment_admin_2024@mongodb:27017
      - HDFS_NAMENODE=hdfs://namenode:9000
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./logs:/app/logs
      - ./models:/app/models
    networks:
      - sentiment-network
    restart: unless-stopped

  # ==================== SPARK BATCH (Batch Layer) ====================
  spark-batch:
    build:
      context: .
      dockerfile: ./docker/spark-batch/Dockerfile
    container_name: spark-batch
    hostname: spark-batch
    depends_on:
      spark-master:
        condition: service_healthy
      namenode:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077
      - HDFS_NAMENODE=hdfs://namenode:9000
      - MONGODB_URI=mongodb://admin:sentiment_admin_2024@mongodb:27017
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./logs:/app/logs
      - ./models:/app/models
    networks:
      - sentiment-network
    restart: unless-stopped

  # ==================== SERVING API ====================
  serving-api:
    build:
      context: .
      dockerfile: ./docker/api/Dockerfile
    container_name: serving-api
    hostname: serving-api
    depends_on:
      redis:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MONGODB_URI=mongodb://admin:sentiment_admin_2024@mongodb:27017
    volumes:
      - ./src:/app/src
      - ./config:/app/config
      - ./logs:/app/logs
    networks:
      - sentiment-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # ==================== PROMETHEUS (Monitoring) ====================
  prometheus:
    image: prom/prometheus:v2.47.0
    container_name: prometheus
    hostname: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    networks:
      - sentiment-network

  # ==================== GRAFANA (Visualization) ====================
  grafana:
    image: grafana/grafana:10.1.0
    container_name: grafana
    hostname: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=sentiment_grafana_2024
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docker/grafana/provisioning:/etc/grafana/provisioning:ro
    networks:
      - sentiment-network
    depends_on:
      - prometheus

  # ==================== FRONTEND ====================
  frontend:
    build:
      context: .
      dockerfile: ./docker/frontend/Dockerfile
    container_name: frontend
    hostname: frontend
    ports:
      - "5173:5173"
    environment:
      - VITE_API_URL=http://localhost:8000
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
    networks:
      - sentiment-network
    depends_on:
      - serving-api

networks:
  sentiment-network:
    driver: bridge
    name: sentiment-network

volumes:
  zookeeper_data:
  zookeeper_log:
  kafka_data:
  hadoop_namenode:
  hadoop_datanode:
  spark_data:
  redis_data:
  mongodb_data:
  prometheus_data:
  grafana_data:
